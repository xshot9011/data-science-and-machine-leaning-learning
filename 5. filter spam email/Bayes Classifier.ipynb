{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import walk\n",
    "from os.path import join\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer, SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from wordcloud import WordCloud\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLE_FILE = 'SpamData/01_Processing/practice_email.txt'\n",
    "SPAM_1_PATH = 'SpamData/01_Processing/spam_assassin_corpus/spam_1/'\n",
    "SPAM_2_PATH = 'SpamData/01_Processing/spam_assassin_corpus/spam_2/'\n",
    "NON_SPAM_1_PATH = 'SpamData/01_Processing/spam_assassin_corpus/easy_ham_1/'\n",
    "NON_SPAM_2_PATH = 'SpamData/01_Processing/spam_assassin_corpus/easy_ham_2/'\n",
    "SPAM = 1\n",
    "NON_SPAM = 0\n",
    "\n",
    "DATA_PATH = 'email-data.json'\n",
    "TRAINING_DATA_FILE = 'data-grouped/train-data.txt'\n",
    "TEST_DATA_FILE = 'data-grouped/test-data.txt'\n",
    "\n",
    "VOCAB_SIZE = 2500\n",
    "\n",
    "WHALE_FILE = 'SpamData/01_Processing/wordcloud_resources/whale-icon.png'\n",
    "THUMBS_UP_FILE = 'SpamData/01_Processing/wordcloud_resources/thumbs-up.png'\n",
    "THUMBS_DOWN_FILE = 'SpamData/01_Processing/wordcloud_resources/thumbs-down.png'\n",
    "FONT_PATH = 'SpamData/01_Processing/wordcloud_resources/OpenSansCondensed-Bold.ttf'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(EXAMPLE_FILE, encoding='latin-1')\n",
    "is_body = False\n",
    "lines = []\n",
    "for line in file:\n",
    "    if is_body:\n",
    "        lines.append(line)\n",
    "    elif line == '\\n':\n",
    "        is_body = True\n",
    "file.close()\n",
    "\n",
    "email_body = '\\n'.join(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Generator Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_square(n):\n",
    "    for number in range(n):\n",
    "        yield number ** 2\n",
    "\n",
    "generate_square(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in generate_square(5):\n",
    "    print(i, end=' ')\n",
    "\n",
    "# สาเหตุที่ต้องใช้ก็คือมันมีการจำ state และเมื่อเราเล่นกับ dataset ใหญ่ๆ\n",
    "# ลองนึกภาพว่าคำนวณก้อนเท่าบ้านออกมาอะ ขนาดข้อมูลนะ ใช้เวลานานมากด้วยกว่าจะรัน state ถัดไปได้"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Email body extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_body_generator(path):\n",
    "    for root, dir_names, file_names in walk(path):\n",
    "        for file_name in file_names:\n",
    "            file = open(join(root, file_name), encoding='latin-1')\n",
    "            is_body = False\n",
    "            lines = []\n",
    "            for line in file:\n",
    "                if is_body:\n",
    "                    lines.append(line)\n",
    "                elif line == '\\n':\n",
    "                    is_body = True\n",
    "            file.close()\n",
    "            email_body = '\\n'.join(lines)\n",
    "            yield file_name, email_body "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_df_from_directory(path, classification):\n",
    "    rows = []\n",
    "    row_names = []\n",
    "    for file_name, email_body in email_body_generator(path):\n",
    "        rows.append({'MESSAGE': email_body, 'CATEGORY': classification})\n",
    "        row_names.append(file_name)\n",
    "    return pd.DataFrame(rows, index=row_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you dont have data-email.csv file\n",
    "df = get_df_from_directory(SPAM_1_PATH, SPAM)\n",
    "df = df.append(get_df_from_directory(SPAM_2_PATH, SPAM))\n",
    "df = df.append(get_df_from_directory(NON_SPAM_1_PATH, NON_SPAM))\n",
    "df = df.append(get_df_from_directory(NON_SPAM_2_PATH, NON_SPAM))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MESSAGE</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Tr...</td>\n",
       "      <td>1</td>\n",
       "      <td>00001.7848dde101aa985090474a91ec93fcf0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1) Fight The Risk of Cancer!\\n\\nhttp://www.adc...</td>\n",
       "      <td>1</td>\n",
       "      <td>00002.d94f1b97e48ed3b553b3508d116e6a09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1) Fight The Risk of Cancer!\\n\\nhttp://www.adc...</td>\n",
       "      <td>1</td>\n",
       "      <td>00003.2ee33bc6eacdb11f38d052c44819ba6c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>##############################################...</td>\n",
       "      <td>1</td>\n",
       "      <td>00004.eac8de8d759b7e74154f142194282724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I thought you might like these:\\n\\n1) Slim Dow...</td>\n",
       "      <td>1</td>\n",
       "      <td>00005.57696a39d7d84318ce497886896bf90d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5791</th>\n",
       "      <td>http://news.bbc.co.uk/1/hi/england/2515127.stm...</td>\n",
       "      <td>0</td>\n",
       "      <td>01396.61983fbe6ec43f55fd44e30fce24ffa6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5792</th>\n",
       "      <td>&gt; &gt;-- be careful when using this one.) Also, t...</td>\n",
       "      <td>0</td>\n",
       "      <td>01397.9f9ef4c2a8dc012d80f2ce2d3473d3b7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5793</th>\n",
       "      <td>&gt;&gt;&gt;&gt;&gt; \"SM\" == Skip Montanaro &lt;skip@pobox.com&gt; ...</td>\n",
       "      <td>0</td>\n",
       "      <td>01398.169b51731fe569f42169ae8f948ec676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5794</th>\n",
       "      <td>So then, \"Mark Hammond\" &lt;mhammond@skippinet.co...</td>\n",
       "      <td>0</td>\n",
       "      <td>01399.ca6b00b7b341bbde9a9ea3dd6a7bf896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5795</th>\n",
       "      <td>Hi there,\\n\\n\\n\\nNow this is probably of no us...</td>\n",
       "      <td>0</td>\n",
       "      <td>01400.f897f0931e461e7b2e964d28e927c35e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5796 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                MESSAGE  CATEGORY  \\\n",
       "id                                                                  \n",
       "0     <!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Tr...         1   \n",
       "1     1) Fight The Risk of Cancer!\\n\\nhttp://www.adc...         1   \n",
       "2     1) Fight The Risk of Cancer!\\n\\nhttp://www.adc...         1   \n",
       "3     ##############################################...         1   \n",
       "4     I thought you might like these:\\n\\n1) Slim Dow...         1   \n",
       "...                                                 ...       ...   \n",
       "5791  http://news.bbc.co.uk/1/hi/england/2515127.stm...         0   \n",
       "5792  > >-- be careful when using this one.) Also, t...         0   \n",
       "5793  >>>>> \"SM\" == Skip Montanaro <skip@pobox.com> ...         0   \n",
       "5794  So then, \"Mark Hammond\" <mhammond@skippinet.co...         0   \n",
       "5795  Hi there,\\n\\n\\n\\nNow this is probably of no us...         0   \n",
       "\n",
       "                                   file_name  \n",
       "id                                            \n",
       "0     00001.7848dde101aa985090474a91ec93fcf0  \n",
       "1     00002.d94f1b97e48ed3b553b3508d116e6a09  \n",
       "2     00003.2ee33bc6eacdb11f38d052c44819ba6c  \n",
       "3     00004.eac8de8d759b7e74154f142194282724  \n",
       "4     00005.57696a39d7d84318ce497886896bf90d  \n",
       "...                                      ...  \n",
       "5791  01396.61983fbe6ec43f55fd44e30fce24ffa6  \n",
       "5792  01397.9f9ef4c2a8dc012d80f2ce2d3473d3b7  \n",
       "5793  01398.169b51731fe569f42169ae8f948ec676  \n",
       "5794  01399.ca6b00b7b341bbde9a9ea3dd6a7bf896  \n",
       "5795  01400.f897f0931e461e7b2e964d28e927c35e  \n",
       "\n",
       "[5796 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# else:  $read it\n",
    "# can skip to explore and visualisation\n",
    "df = pd.read_csv(DATA_PATH.replace('json', 'csv'))\n",
    "df = df.set_index('id')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning: Checking for Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing valeus\n",
    "print(df['MESSAGE'].isnull().values.any(), '\\n')\n",
    "print(df['MESSAGE'].isnull().value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for empty email\n",
    "print((df['MESSAGE'].str.len() == 0).values.any(), '\\n')\n",
    "print((df['MESSAGE'].str.len() == 0).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locate emptry email\n",
    "print(df['MESSAGE'].str.len()==0)\n",
    "df[df['MESSAGE'].str.len()==0].index  # get the index, name which match given condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.index.get_loc('cmds')  # return narray type: boolean\n",
    "#df[df.index.get_loc('cmds')]\n",
    "#df.index\n",
    "\n",
    "a = df[df['MESSAGE'].str.len()==0].index\n",
    "df.loc[['cmds']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove System file Entries from DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['cmds'], inplace=True)  # inplace make chahge with df, drop with index of list of index's name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_id = range(0, len(df.index))\n",
    "df['id'] = doc_id\n",
    "df['file_name'] = df.index\n",
    "df = df.set_index('id')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file using pandas\n",
    "df.to_json(DATA_PATH)\n",
    "df.to_csv(DATA_PATH.replace('json', 'csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore & Data visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CATEGORY'].value_counts()\n",
    "non_spam_amount = df['CATEGORY'].value_counts()[0]\n",
    "spam_amount = df['CATEGORY'].value_counts()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [spam_amount, non_spam_amount]\n",
    "categ_names = ['Spam', 'Non-Spam']\n",
    "plt.figure(figsize=[8, 8])\n",
    "plt.pie(sizes, labels=categ_names, startangle=90, textprops={'fontsize': 16}, autopct='%1.0f%%',\n",
    "        explode=[0, 0.1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[8, 8])\n",
    "plt.pie(sizes, labels=categ_names, startangle=90, textprops={'fontsize': 16}, autopct='%1.0f%%',\n",
    "        pctdistance=0.8)\n",
    "plt.gca().add_artist(plt.Circle((0, 0), radius=0.6, fc='white'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pre-processing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to Lower Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = 'Prayut is bad soldier. That\\'s True'\n",
    "word.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the NLTK Resources (Tokenizer & Stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenize(word.lower())  # like split.(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop words  & Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example nltk resource for data visualisation\n",
    "nltk.download('gutenberg')\n",
    "nltk.download('shakespeare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = 'Prayut do and did Bad. That\\'s True. To be or not to be. He should not have done. Inovation'\n",
    "words = word_tokenize(word.lower())\n",
    "filterd_words = []\n",
    "stemmer = PorterStemmer()\n",
    "#stemmer = SnowballStemmer('english')\n",
    "\n",
    "for word in words:\n",
    "    if word not in stop_words and word.isalpha():\n",
    "        stemmed_word = stemmer.stem(word)\n",
    "        filterd_words.append(stemmed_word)\n",
    "    \n",
    "filterd_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('>'.isalpha())\n",
    "print('Ps'.isalpha())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing HTML tag in email body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at[[row], [column name]]\n",
    "soup = BeautifulSoup(df.at[2, 'MESSAGE'], 'html.parser')\n",
    "print(soup.prettify())\n",
    "print(soup.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clean_message(message, stemmer=PorterStemmer(), stop_words=set(stopwords.words('english'))):\n",
    "    message = BeautifulSoup(message, 'html.parser').get_text().lower()  # remove html tag and set to lowwer\n",
    "    words = word_tokenize(message)  # split the word\n",
    "    filtered_words = []\n",
    "    \n",
    "    for word in words:\n",
    "        # remove stop word and punctuation\n",
    "        if word not in stop_words and word.isalpha():\n",
    "            filtered_words.append(stemmer.stem(word))\n",
    "    \n",
    "    return filtered_words  # list of filtered words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_clean_message(df.at[2, 'MESSAGE'])  # at is used to access the particular cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Apply Cleaning and Tokenisation to all messages\n",
    "\n",
    "#### at[row, column] \n",
    "#### at[1, 2] >> at[1, 'the second column'] is the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to select more than 1 row, work on datagrame and series\n",
    "print(type(df.iloc[5:11]))  # iloc >> integer location\n",
    "print(df['MESSAGE'].iloc[5:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\b\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:389: UserWarning: \"http://www.post-gazette.com/columnists/20020905brian5\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 30.3 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MESSAGE</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[save, life, insur, spend, life, quot, save, g...</td>\n",
       "      <td>1</td>\n",
       "      <td>00001.7848dde101aa985090474a91ec93fcf0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[fight, risk, cancer, http, slim, guarante, lo...</td>\n",
       "      <td>1</td>\n",
       "      <td>00002.d94f1b97e48ed3b553b3508d116e6a09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[fight, risk, cancer, http, slim, guarante, lo...</td>\n",
       "      <td>1</td>\n",
       "      <td>00003.2ee33bc6eacdb11f38d052c44819ba6c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[adult, club, offer, free, membership, instant...</td>\n",
       "      <td>1</td>\n",
       "      <td>00004.eac8de8d759b7e74154f142194282724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[thought, might, like, slim, guarante, lose, l...</td>\n",
       "      <td>1</td>\n",
       "      <td>00005.57696a39d7d84318ce497886896bf90d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5791</th>\n",
       "      <td>[http, bizarr, collect, stuf, anim, could, fet...</td>\n",
       "      <td>0</td>\n",
       "      <td>01396.61983fbe6ec43f55fd44e30fce24ffa6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5792</th>\n",
       "      <td>[care, use, one, also, realli, cute, thing, ja...</td>\n",
       "      <td>0</td>\n",
       "      <td>01397.9f9ef4c2a8dc012d80f2ce2d3473d3b7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5793</th>\n",
       "      <td>[sm, skip, montanaro, write, jeremi, put, anot...</td>\n",
       "      <td>0</td>\n",
       "      <td>01398.169b51731fe569f42169ae8f948ec676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5794</th>\n",
       "      <td>[mark, hammond, like, given, zodb, sound, attr...</td>\n",
       "      <td>0</td>\n",
       "      <td>01399.ca6b00b7b341bbde9a9ea3dd6a7bf896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5795</th>\n",
       "      <td>[hi, probabl, use, whatsoev, also, problem, re...</td>\n",
       "      <td>0</td>\n",
       "      <td>01400.f897f0931e461e7b2e964d28e927c35e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5796 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                MESSAGE  CATEGORY  \\\n",
       "id                                                                  \n",
       "0     [save, life, insur, spend, life, quot, save, g...         1   \n",
       "1     [fight, risk, cancer, http, slim, guarante, lo...         1   \n",
       "2     [fight, risk, cancer, http, slim, guarante, lo...         1   \n",
       "3     [adult, club, offer, free, membership, instant...         1   \n",
       "4     [thought, might, like, slim, guarante, lose, l...         1   \n",
       "...                                                 ...       ...   \n",
       "5791  [http, bizarr, collect, stuf, anim, could, fet...         0   \n",
       "5792  [care, use, one, also, realli, cute, thing, ja...         0   \n",
       "5793  [sm, skip, montanaro, write, jeremi, put, anot...         0   \n",
       "5794  [mark, hammond, like, given, zodb, sound, attr...         0   \n",
       "5795  [hi, probabl, use, whatsoev, also, problem, re...         0   \n",
       "\n",
       "                                   file_name  \n",
       "id                                            \n",
       "0     00001.7848dde101aa985090474a91ec93fcf0  \n",
       "1     00002.d94f1b97e48ed3b553b3508d116e6a09  \n",
       "2     00003.2ee33bc6eacdb11f38d052c44819ba6c  \n",
       "3     00004.eac8de8d759b7e74154f142194282724  \n",
       "4     00005.57696a39d7d84318ce497886896bf90d  \n",
       "...                                      ...  \n",
       "5791  01396.61983fbe6ec43f55fd44e30fce24ffa6  \n",
       "5792  01397.9f9ef4c2a8dc012d80f2ce2d3473d3b7  \n",
       "5793  01398.169b51731fe569f42169ae8f948ec676  \n",
       "5794  01399.ca6b00b7b341bbde9a9ea3dd6a7bf896  \n",
       "5795  01400.f897f0931e461e7b2e964d28e927c35e  \n",
       "\n",
       "[5796 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df['MESSAGE'] = df['MESSAGE'].apply(get_clean_message)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Logic to Slice DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[given narray with true false condition]\n",
    "spam_emails_index = df[df['CATEGORY'] == 1].index\n",
    "non_spam_emails_index = df[df['CATEGORY'] == 0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.loc[spam_emails_index])\n",
    "print(df.loc[non_spam_emails_index])\n",
    "# locate > gets rows (or columns) with particular labels from the index.\n",
    "# iloc > integer locate > gets rows (or columns) at particular positions in the index (so it only takes integers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# จากด้านบนเราคิดว่าสามารถย่อมันเหลือแค่นิดเดียวก็ได้นิทำทำไมตั้งหลายรอบ\n",
    "#df[given narray with true false condition]\n",
    "spam_emails_df = df[df['CATEGORY'] == 1]\n",
    "non_spam_emails_df = df[df['CATEGORY'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### misunderstand "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# find the total number of words in clened dataset of both spam and non-spam email bodies\n",
    "# find 10 common use in both spam and non-spam email bodies\n",
    "# I do, >> misunderstand about the given command from the teacher\n",
    "words_len = []\n",
    "for index in spam_emails_index:\n",
    "    words_len.append(len(spam_emails_df.loc[index].MESSAGE))\n",
    "spam_word_amount = sum(words_len)\n",
    "print('spam word amoun :', spam_word_amount)\n",
    "for index in non_spam_emails_index:\n",
    "    words_len.append(len(non_spam_emails_df.loc[index].MESSAGE))\n",
    "non_spam_word_amount = sum(words_len) - spam_word_amount\n",
    "print('non-spam word amoun :', non_spam_word_amount)\n",
    "\n",
    "df['words_amount'] = pd.Series(words_len)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### teacher do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam word amoun : 320571\n",
      "non-spam word amoun : 441403\n"
     ]
    }
   ],
   "source": [
    "spam_word_series = df['MESSAGE'].loc[spam_emails_index]\n",
    "non_spam_word_series = df['MESSAGE'].loc[non_spam_emails_index]\n",
    "spam_words = pd.Series([word for words_list in spam_word_series for word in words_list])\n",
    "non_spam_words = pd.Series([word for words_list in non_spam_word_series for word in words_list])\n",
    "print('spam word amoun :', len(spam_words))\n",
    "print('non-spam word amoun :', len(non_spam_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('total number of word :', spam_words.value_counts().shape[0])\n",
    "print(spam_words.value_counts()[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('total number of word :', non_spam_words.value_counts().shape[0])\n",
    "print(non_spam_words.value_counts()[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preinstall open anaconda termial\n",
    "# > conda install -c conda-forge wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_cloud = WordCloud().generate(email_body)\n",
    "plt.imshow(word_cloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = nltk.corpus.gutenberg.words('melville-moby_dick.txt')\n",
    "#print(type(example))\n",
    "#print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = [''.join(word) for word in example]\n",
    "#print(type(example))\n",
    "#print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = ' '.join(example)\n",
    "#print(type(example))\n",
    "#print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icon = Image.open(WHALE_FILE)\n",
    "mask = Image.new(mode='RGB', size=icon.size, color=(255, 255, 255))  # create all white image\n",
    "mask.paste(icon, box=icon)  # paste the black one on it\n",
    "rgb_array = np.array(mask)  # get new image >> convert to array\n",
    "\n",
    "word_cloud = WordCloud(mask=rgb_array, background_color='white',\n",
    "                       max_words=1000, colormap='ocean').generate(example)\n",
    "plt.figure(figsize=[16, 8])\n",
    "plt.imshow(word_cloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Cloud of Non-Spam and Spam Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "icon = Image.open(THUMBS_DOWN_FILE)\n",
    "mask = Image.new(mode='RGB', size=icon.size, color=(255, 255, 255))  # create all white image\n",
    "mask.paste(icon, box=icon)  # paste the black one on it\n",
    "rgb_array = np.array(mask)  # get new image >> convert to array\n",
    "\n",
    "word_cloud = WordCloud(mask=rgb_array, background_color='white',\n",
    "                       max_words=1300, colormap='gist_heat', font_path=FONT_PATH)\\\n",
    "                       .generate(' '.join(spam_words))\n",
    "plt.figure(figsize=[20, 12])\n",
    "plt.imshow(word_cloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "icon = Image.open(THUMBS_UP_FILE)\n",
    "mask = Image.new(mode='RGB', size=icon.size, color=(255, 255, 255))  # create all white image\n",
    "mask.paste(icon, box=icon)  # paste the black one on it\n",
    "rgb_array = np.array(mask)  # get new image >> convert to array\n",
    "\n",
    "word_cloud = WordCloud(mask=rgb_array, background_color='white',\n",
    "                       max_words=1000, colormap='gist_heat', font_path=FONT_PATH)\\\n",
    "                       .generate(' '.join(non_spam_words))\n",
    "plt.figure(figsize=[16, 8])\n",
    "plt.imshow(word_cloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Vocabulary & Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "http      3101\n",
       "email     3094\n",
       "free      2555\n",
       "click     2058\n",
       "receiv    1987\n",
       "list      1974\n",
       "get       1903\n",
       "pleas     1842\n",
       "busi      1792\n",
       "order     1743\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_spam_words = spam_words.value_counts()[:VOCAB_SIZE]  # top most 2500 used in spam email\n",
    "freq_spam_words[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Vocabulary DataFrame with word_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WORD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WORD_ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>click</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>receiv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>ghetto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>hawaiian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>civilian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>earth</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             WORD\n",
       "WORD_ID          \n",
       "0            http\n",
       "1           email\n",
       "2            free\n",
       "3           click\n",
       "4          receiv\n",
       "...           ...\n",
       "2495       ghetto\n",
       "2496       indian\n",
       "2497     hawaiian\n",
       "2498     civilian\n",
       "2499        earth\n",
       "\n",
       "[2500 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_id = list(range(0, VOCAB_SIZE))\n",
    "vocab_df = pd.DataFrame({'WORD': freq_spam_words.index}, index=_id)\n",
    "vocab_df.to_csv('spam_word.csv')\n",
    "vocab_df.index.name = 'WORD_ID'\n",
    "vocab_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_in_vocab(word):\n",
    "    return True if word in vocab_df['WORD'].values else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_in_vocab('free')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exsecise find the email with the most number of words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam word amoun : 320571\n",
      "non-spam word amoun : 441403\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MESSAGE</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>file_name</th>\n",
       "      <th>words_amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[save, life, insur, spend, life, quot, save, g...</td>\n",
       "      <td>1</td>\n",
       "      <td>00001.7848dde101aa985090474a91ec93fcf0</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[fight, risk, cancer, http, slim, guarante, lo...</td>\n",
       "      <td>1</td>\n",
       "      <td>00002.d94f1b97e48ed3b553b3508d116e6a09</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[fight, risk, cancer, http, slim, guarante, lo...</td>\n",
       "      <td>1</td>\n",
       "      <td>00003.2ee33bc6eacdb11f38d052c44819ba6c</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[adult, club, offer, free, membership, instant...</td>\n",
       "      <td>1</td>\n",
       "      <td>00004.eac8de8d759b7e74154f142194282724</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[thought, might, like, slim, guarante, lose, l...</td>\n",
       "      <td>1</td>\n",
       "      <td>00005.57696a39d7d84318ce497886896bf90d</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              MESSAGE  CATEGORY  \\\n",
       "id                                                                \n",
       "0   [save, life, insur, spend, life, quot, save, g...         1   \n",
       "1   [fight, risk, cancer, http, slim, guarante, lo...         1   \n",
       "2   [fight, risk, cancer, http, slim, guarante, lo...         1   \n",
       "3   [adult, club, offer, free, membership, instant...         1   \n",
       "4   [thought, might, like, slim, guarante, lose, l...         1   \n",
       "\n",
       "                                 file_name  words_amount  \n",
       "id                                                        \n",
       "0   00001.7848dde101aa985090474a91ec93fcf0            92  \n",
       "1   00002.d94f1b97e48ed3b553b3508d116e6a09            56  \n",
       "2   00003.2ee33bc6eacdb11f38d052c44819ba6c            44  \n",
       "3   00004.eac8de8d759b7e74154f142194282724           205  \n",
       "4   00005.57696a39d7d84318ce497886896bf90d            45  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_len = []\n",
    "for index in spam_emails_index:\n",
    "    words_len.append(len(spam_emails_df.loc[index].MESSAGE))\n",
    "spam_word_amount = sum(words_len)\n",
    "print('spam word amoun :', spam_word_amount)\n",
    "for index in non_spam_emails_index:\n",
    "    words_len.append(len(non_spam_emails_df.loc[index].MESSAGE))\n",
    "non_spam_word_amount = sum(words_len) - spam_word_amount\n",
    "print('non-spam word amoun :', non_spam_word_amount)\n",
    "\n",
    "df['words_amount'] = pd.Series(words_len)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MESSAGE</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>file_name</th>\n",
       "      <th>words_amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5775</th>\n",
       "      <td>[yahoo, group, sponsor, dvd, free, p, join, ht...</td>\n",
       "      <td>0</td>\n",
       "      <td>01380.e3fad5af747d3a110008f94a046bf31b</td>\n",
       "      <td>7671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                MESSAGE  CATEGORY  \\\n",
       "id                                                                  \n",
       "5775  [yahoo, group, sponsor, dvd, free, p, join, ht...         0   \n",
       "\n",
       "                                   file_name  words_amount  \n",
       "id                                                          \n",
       "5775  01380.e3fad5af747d3a110008f94a046bf31b          7671  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longest_email = df[df['words_amount'].max() == df['words_amount']]\n",
    "longest_email"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Features & Sparse Matrix\n",
    "\n",
    "### Creating a DaraFrame with one word per data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "0       [save, life, insur, spend, life, quot, save, g...\n",
       "1       [fight, risk, cancer, http, slim, guarante, lo...\n",
       "2       [fight, risk, cancer, http, slim, guarante, lo...\n",
       "3       [adult, club, offer, free, membership, instant...\n",
       "4       [thought, might, like, slim, guarante, lose, l...\n",
       "                              ...                        \n",
       "1891    [want, boss, train, home, studi, thousand, peo...\n",
       "1892    [messag, mime, format, prefer, doctor, order, ...\n",
       "1893    [dear, subscrib, could, show, way, get, visito...\n",
       "1894    [custom, appreci, sale, express, appreci, loya...\n",
       "1895    [attn, strictli, confidenti, pleas, introduc, ...\n",
       "Name: MESSAGE, Length: 1896, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_emails_df['MESSAGE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>7661</th>\n",
       "      <th>7662</th>\n",
       "      <th>7663</th>\n",
       "      <th>7664</th>\n",
       "      <th>7665</th>\n",
       "      <th>7666</th>\n",
       "      <th>7667</th>\n",
       "      <th>7668</th>\n",
       "      <th>7669</th>\n",
       "      <th>7670</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>save</td>\n",
       "      <td>life</td>\n",
       "      <td>insur</td>\n",
       "      <td>spend</td>\n",
       "      <td>life</td>\n",
       "      <td>quot</td>\n",
       "      <td>save</td>\n",
       "      <td>g</td>\n",
       "      <td>famili</td>\n",
       "      <td>financi</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fight</td>\n",
       "      <td>risk</td>\n",
       "      <td>cancer</td>\n",
       "      <td>http</td>\n",
       "      <td>slim</td>\n",
       "      <td>guarante</td>\n",
       "      <td>lose</td>\n",
       "      <td>lb</td>\n",
       "      <td>day</td>\n",
       "      <td>http</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fight</td>\n",
       "      <td>risk</td>\n",
       "      <td>cancer</td>\n",
       "      <td>http</td>\n",
       "      <td>slim</td>\n",
       "      <td>guarante</td>\n",
       "      <td>lose</td>\n",
       "      <td>lb</td>\n",
       "      <td>day</td>\n",
       "      <td>http</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adult</td>\n",
       "      <td>club</td>\n",
       "      <td>offer</td>\n",
       "      <td>free</td>\n",
       "      <td>membership</td>\n",
       "      <td>instant</td>\n",
       "      <td>access</td>\n",
       "      <td>site</td>\n",
       "      <td>user</td>\n",
       "      <td>name</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thought</td>\n",
       "      <td>might</td>\n",
       "      <td>like</td>\n",
       "      <td>slim</td>\n",
       "      <td>guarante</td>\n",
       "      <td>lose</td>\n",
       "      <td>lb</td>\n",
       "      <td>day</td>\n",
       "      <td>http</td>\n",
       "      <td>fight</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5791</th>\n",
       "      <td>http</td>\n",
       "      <td>bizarr</td>\n",
       "      <td>collect</td>\n",
       "      <td>stuf</td>\n",
       "      <td>anim</td>\n",
       "      <td>could</td>\n",
       "      <td>fetch</td>\n",
       "      <td>sold</td>\n",
       "      <td>cornwal</td>\n",
       "      <td>museum</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5792</th>\n",
       "      <td>care</td>\n",
       "      <td>use</td>\n",
       "      <td>one</td>\n",
       "      <td>also</td>\n",
       "      <td>realli</td>\n",
       "      <td>cute</td>\n",
       "      <td>thing</td>\n",
       "      <td>japanes</td>\n",
       "      <td>av</td>\n",
       "      <td>girl</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5793</th>\n",
       "      <td>sm</td>\n",
       "      <td>skip</td>\n",
       "      <td>montanaro</td>\n",
       "      <td>write</td>\n",
       "      <td>jeremi</td>\n",
       "      <td>put</td>\n",
       "      <td>anoth</td>\n",
       "      <td>way</td>\n",
       "      <td>interest</td>\n",
       "      <td>hear</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5794</th>\n",
       "      <td>mark</td>\n",
       "      <td>hammond</td>\n",
       "      <td>like</td>\n",
       "      <td>given</td>\n",
       "      <td>zodb</td>\n",
       "      <td>sound</td>\n",
       "      <td>attract</td>\n",
       "      <td>would</td>\n",
       "      <td>packag</td>\n",
       "      <td>hundr</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5795</th>\n",
       "      <td>hi</td>\n",
       "      <td>probabl</td>\n",
       "      <td>use</td>\n",
       "      <td>whatsoev</td>\n",
       "      <td>also</td>\n",
       "      <td>problem</td>\n",
       "      <td>regard</td>\n",
       "      <td>nvidia</td>\n",
       "      <td>two</td>\n",
       "      <td>machin</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5796 rows × 7671 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0        1          2         3           4         5        6     \\\n",
       "0        save     life      insur     spend        life      quot     save   \n",
       "1       fight     risk     cancer      http        slim  guarante     lose   \n",
       "2       fight     risk     cancer      http        slim  guarante     lose   \n",
       "3       adult     club      offer      free  membership   instant   access   \n",
       "4     thought    might       like      slim    guarante      lose       lb   \n",
       "...       ...      ...        ...       ...         ...       ...      ...   \n",
       "5791     http   bizarr    collect      stuf        anim     could    fetch   \n",
       "5792     care      use        one      also      realli      cute    thing   \n",
       "5793       sm     skip  montanaro     write      jeremi       put    anoth   \n",
       "5794     mark  hammond       like     given        zodb     sound  attract   \n",
       "5795       hi  probabl        use  whatsoev        also   problem   regard   \n",
       "\n",
       "         7         8        9     ...  7661  7662  7663  7664  7665  7666  \\\n",
       "0           g    famili  financi  ...  None  None  None  None  None  None   \n",
       "1          lb       day     http  ...  None  None  None  None  None  None   \n",
       "2          lb       day     http  ...  None  None  None  None  None  None   \n",
       "3        site      user     name  ...  None  None  None  None  None  None   \n",
       "4         day      http    fight  ...  None  None  None  None  None  None   \n",
       "...       ...       ...      ...  ...   ...   ...   ...   ...   ...   ...   \n",
       "5791     sold   cornwal   museum  ...  None  None  None  None  None  None   \n",
       "5792  japanes        av     girl  ...  None  None  None  None  None  None   \n",
       "5793      way  interest     hear  ...  None  None  None  None  None  None   \n",
       "5794    would    packag    hundr  ...  None  None  None  None  None  None   \n",
       "5795   nvidia       two   machin  ...  None  None  None  None  None  None   \n",
       "\n",
       "      7667  7668  7669  7670  \n",
       "0     None  None  None  None  \n",
       "1     None  None  None  None  \n",
       "2     None  None  None  None  \n",
       "3     None  None  None  None  \n",
       "4     None  None  None  None  \n",
       "...    ...   ...   ...   ...  \n",
       "5791  None  None  None  None  \n",
       "5792  None  None  None  None  \n",
       "5793  None  None  None  None  \n",
       "5794  None  None  None  None  \n",
       "5795  None  None  None  None  \n",
       "\n",
       "[5796 rows x 7671 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_per_email_list = df['MESSAGE'].tolist()  # get the list for each MESSAGE of email\n",
    "words_column_df = pd.DataFrame.from_records(words_per_email_list)\n",
    "words_column_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(words_column_df, df['CATEGORY'],\n",
    "                                                   test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples 4057\n",
      "Number of testing samples 1739\n",
      "Fraction of training set 0.6999654934437544\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>7661</th>\n",
       "      <th>7662</th>\n",
       "      <th>7663</th>\n",
       "      <th>7664</th>\n",
       "      <th>7665</th>\n",
       "      <th>7666</th>\n",
       "      <th>7667</th>\n",
       "      <th>7668</th>\n",
       "      <th>7669</th>\n",
       "      <th>7670</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOC_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4844</th>\n",
       "      <td>ye</td>\n",
       "      <td>inde</td>\n",
       "      <td>agent</td>\n",
       "      <td>directori</td>\n",
       "      <td>verita</td>\n",
       "      <td>cd</td>\n",
       "      <td>unix</td>\n",
       "      <td>subdirectori</td>\n",
       "      <td>file</td>\n",
       "      <td>call</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4727</th>\n",
       "      <td>problem</td>\n",
       "      <td>come</td>\n",
       "      <td>tri</td>\n",
       "      <td>instal</td>\n",
       "      <td>harddissssk</td>\n",
       "      <td>like</td>\n",
       "      <td>alreadi</td>\n",
       "      <td>mount</td>\n",
       "      <td>http</td>\n",
       "      <td>yahoo</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5022</th>\n",
       "      <td>origin</td>\n",
       "      <td>messag</td>\n",
       "      <td>date</td>\n",
       "      <td>mon</td>\n",
       "      <td>aug</td>\n",
       "      <td>chad</td>\n",
       "      <td>norwood</td>\n",
       "      <td>sven</td>\n",
       "      <td>cc</td>\n",
       "      <td>subject</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3504</th>\n",
       "      <td>inlin</td>\n",
       "      <td>folk</td>\n",
       "      <td>sever</td>\n",
       "      <td>major</td>\n",
       "      <td>internet</td>\n",
       "      <td>outag</td>\n",
       "      <td>morn</td>\n",
       "      <td>across</td>\n",
       "      <td>major</td>\n",
       "      <td>provid</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3921</th>\n",
       "      <td>url</td>\n",
       "      <td>http</td>\n",
       "      <td>date</td>\n",
       "      <td>bath</td>\n",
       "      <td>chronicl</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7671 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0       1      2          3            4      5        6     \\\n",
       "DOC_ID                                                                   \n",
       "4844         ye    inde  agent  directori       verita     cd     unix   \n",
       "4727    problem    come    tri     instal  harddissssk   like  alreadi   \n",
       "5022     origin  messag   date        mon          aug   chad  norwood   \n",
       "3504      inlin    folk  sever      major     internet  outag     morn   \n",
       "3921        url    http   date       bath     chronicl   None     None   \n",
       "\n",
       "                7      8        9     ...  7661  7662  7663  7664  7665  7666  \\\n",
       "DOC_ID                                ...                                       \n",
       "4844    subdirectori   file     call  ...  None  None  None  None  None  None   \n",
       "4727           mount   http    yahoo  ...  None  None  None  None  None  None   \n",
       "5022            sven     cc  subject  ...  None  None  None  None  None  None   \n",
       "3504          across  major   provid  ...  None  None  None  None  None  None   \n",
       "3921            None   None     None  ...  None  None  None  None  None  None   \n",
       "\n",
       "        7667  7668  7669  7670  \n",
       "DOC_ID                          \n",
       "4844    None  None  None  None  \n",
       "4727    None  None  None  None  \n",
       "5022    None  None  None  None  \n",
       "3504    None  None  None  None  \n",
       "3921    None  None  None  None  \n",
       "\n",
       "[5 rows x 7671 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Number of training samples', X_train.shape[0])\n",
    "print('Number of testing samples', X_test.shape[0])\n",
    "print('Fraction of training set', X_train.shape[0]/words_column_df.shape[0])\n",
    "X_train.index.name = 'DOC_ID'\n",
    "X_test.index.name = 'DOC_ID'\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Sparse Matric for the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['http', 'email', 'free', 'click', 'receiv', 'list', 'get', 'pleas',\n",
       "       'busi', 'order',\n",
       "       ...\n",
       "       'strive', 'sic', 'struggl', 'wet', 'merger', 'ghetto', 'indian',\n",
       "       'hawaiian', 'civilian', 'earth'],\n",
       "      dtype='object', name='WORD', length=2500)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index = pd.Index(vocab_df['WORD'])  # top 2500 word's indexs\n",
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.index[112] >> get the name of index(DOC_id) at index 112 >> (DOC_ID)\n",
    "# y_train.at[112] >> get the value at index 112 >> (CATEGORY)\n",
    "# word_index.get_loc('word') >> get the index of giver string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sparse_matrix(df, word_index, labels):\n",
    "    \"\"\"\n",
    "    Return sparse matric as dataframe\n",
    "    df: A dataframe words in the columns with a document id as an index X_test, X_train\n",
    "    word_index: index of words ordered by word id\n",
    "    labels: catagory as a series y_test, t_train\n",
    "    \"\"\"\n",
    "    row_number = df.shape[0]\n",
    "    column_number = df.shape[1]\n",
    "    word_set = set(word_index)\n",
    "    dict_list = []\n",
    "    \n",
    "    for i in range(row_number):\n",
    "        for j in range(column_number):\n",
    "            word = df.iat[i, j]\n",
    "            if word in word_set:\n",
    "                doc_id = df.index[i]\n",
    "                word_id = word_index.get_loc(word)\n",
    "                category = labels.at[doc_id]\n",
    "                \n",
    "                item = {'LABEL': category, 'DOC_ID': doc_id, 'OCCURENCE': 1, 'WORD_ID': word_id}\n",
    "                \n",
    "                dict_list.append(item)\n",
    "    \n",
    "    return pd.DataFrame(dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sparse_train_df = get_sparse_matrix(X_train, word_index, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>DOC_ID</th>\n",
       "      <th>OCCURENCE</th>\n",
       "      <th>WORD_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4844</td>\n",
       "      <td>1</td>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4844</td>\n",
       "      <td>1</td>\n",
       "      <td>1499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4844</td>\n",
       "      <td>1</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4844</td>\n",
       "      <td>1</td>\n",
       "      <td>558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4844</td>\n",
       "      <td>1</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404311</th>\n",
       "      <td>1</td>\n",
       "      <td>860</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404312</th>\n",
       "      <td>1</td>\n",
       "      <td>860</td>\n",
       "      <td>1</td>\n",
       "      <td>881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404313</th>\n",
       "      <td>1</td>\n",
       "      <td>860</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404314</th>\n",
       "      <td>1</td>\n",
       "      <td>860</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404315</th>\n",
       "      <td>1</td>\n",
       "      <td>860</td>\n",
       "      <td>1</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>404316 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        LABEL  DOC_ID  OCCURENCE  WORD_ID\n",
       "0           0    4844          1      370\n",
       "1           0    4844          1     1499\n",
       "2           0    4844          1      270\n",
       "3           0    4844          1      558\n",
       "4           0    4844          1      172\n",
       "...       ...     ...        ...      ...\n",
       "404311      1     860          1       48\n",
       "404312      1     860          1      881\n",
       "404313      1     860          1       11\n",
       "404314      1     860          1        3\n",
       "404315      1     860          1      133\n",
       "\n",
       "[404316 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Occurrences with Pandas groupby() Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOC_ID</th>\n",
       "      <th>WORD_ID</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>OCCURENCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241948</th>\n",
       "      <td>5795</td>\n",
       "      <td>2077</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241949</th>\n",
       "      <td>5795</td>\n",
       "      <td>2164</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241950</th>\n",
       "      <td>5795</td>\n",
       "      <td>2271</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241951</th>\n",
       "      <td>5795</td>\n",
       "      <td>2360</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241952</th>\n",
       "      <td>5795</td>\n",
       "      <td>2421</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>241953 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        DOC_ID  WORD_ID  LABEL  OCCURENCE\n",
       "0            0        1      1          2\n",
       "1            0        2      1          3\n",
       "2            0        3      1          2\n",
       "3            0        5      1          1\n",
       "4            0        6      1          1\n",
       "...        ...      ...    ...        ...\n",
       "241948    5795     2077      0          1\n",
       "241949    5795     2164      0          7\n",
       "241950    5795     2271      0          1\n",
       "241951    5795     2360      0          1\n",
       "241952    5795     2421      0          1\n",
       "\n",
       "[241953 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_train_df = sparse_train_df.groupby(['DOC_ID', 'WORD_ID', 'LABEL']).sum()\n",
    "sparse_train_df = sparse_train_df.reset_index()\n",
    "sparse_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word : throughout\n",
      "occure : 0\n"
     ]
    }
   ],
   "source": [
    "DOC_ID = 5795\n",
    "WORD_ID = 2197\n",
    "print('word :', vocab_df.at[WORD_ID, 'WORD'])\n",
    "print('occure :', df['MESSAGE'][DOC_ID].count(vocab_df.at[WORD_ID, 'WORD']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Traning Data as .txt File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(TRAINING_DATA_FILE, sparse_train_df, fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## challenge: create sparse matrix for the test data >> do the same just like we did above and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 58 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOC_ID</th>\n",
       "      <th>WORD_ID</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>OCCURENCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110983</th>\n",
       "      <td>5793</td>\n",
       "      <td>1918</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110984</th>\n",
       "      <td>5793</td>\n",
       "      <td>1982</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110985</th>\n",
       "      <td>5793</td>\n",
       "      <td>2209</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110986</th>\n",
       "      <td>5793</td>\n",
       "      <td>2252</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110987</th>\n",
       "      <td>5793</td>\n",
       "      <td>2278</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110988 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        DOC_ID  WORD_ID  LABEL  OCCURENCE\n",
       "0            8        1      1          4\n",
       "1            8        2      1          4\n",
       "2            8        4      1          5\n",
       "3            8        5      1          1\n",
       "4            8        6      1          2\n",
       "...        ...      ...    ...        ...\n",
       "110983    5793     1918      0          1\n",
       "110984    5793     1982      0          3\n",
       "110985    5793     2209      0          1\n",
       "110986    5793     2252      0          1\n",
       "110987    5793     2278      0         25\n",
       "\n",
       "[110988 rows x 4 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "sparse_test_df = get_sparse_matrix(X_test, word_index, y_test)\n",
    "sparse_test_df = sparse_test_df.groupby(['DOC_ID', 'WORD_ID', 'LABEL']).sum()\n",
    "sparse_test_df = sparse_test_df.reset_index()\n",
    "sparse_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(TEST_DATA_FILE, sparse_train_df, fmt='%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing Subtleties and Checking your Understand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We started with 5796 emails. >> split to 4057 emails for training and 1739 emails for testing\n",
    "\n",
    "1. How many individual emails were include in the traning .txt file? Count the number in test_grouped DataFrame.\n",
    "\n",
    "After spritting and shuffing our data, how many emails were included in the X_test DataFrame? Is the same number?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3900\n",
       "1    1896\n",
       "Name: CATEGORY, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['CATEGORY'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual train email amount: 4015\n",
      "Individual test email amount: 1724\n"
     ]
    }
   ],
   "source": [
    "train_doc_ids = set(sparse_train_df['DOC_ID'])\n",
    "test_doc_ids = set(sparse_test_df['DOC_ID'])\n",
    "print('Individual train email amount:', len(train_doc_ids))\n",
    "print('Individual test email amount:', len(test_doc_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{134, 179, 240, 274, 298, 339, 439, 471, 670, 734, 765, 945, 1544, 1670, 1700}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(X_test.index.values) - test_doc_ids "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kiaqicogkiaqicogkiaqicogkiaqicogkiaqicogkiaqicogkiaqicogkjwv']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.MESSAGE[670]  # after clenaing there's no msg with all above emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
